{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé® MASUKA V2 - Complete Google Colab Setup\n",
    "\n",
    "**Single definitive notebook with all fixes applied + Training & Generation!**\n",
    "\n",
    "This notebook provides everything you need:\n",
    "- ‚úÖ Complete setup (PyTorch, Backend, Database, Redis, Celery)\n",
    "- ‚úÖ API testing and diagnostics\n",
    "- ‚úÖ **LoRA training workflow**\n",
    "- ‚úÖ **Image generation with Flux**\n",
    "- ‚úÖ Public API via Ngrok\n",
    "\n",
    "**Expected setup time:** ~10 minutes on first run\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Quick Start:\n",
    "\n",
    "1. **Set Runtime to GPU:** Runtime ‚Üí Change runtime type ‚Üí GPU (T4 recommended)\n",
    "2. **Run Cell 1:** Complete setup (wait ~10 minutes)\n",
    "3. **Run Cell 2:** Test API endpoints\n",
    "4. **Run Cell 5:** Upload images and create dataset\n",
    "5. **Run Cell 6:** Train your LoRA model\n",
    "6. **Run Cell 7:** Generate images!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell1_setup",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title üöÄ CELL 1: Complete Setup (Run Once)\n#@markdown This cell sets up everything: PyTorch, Backend, Database, Redis, Celery, and Ngrok tunnel.\n#@markdown Expected time: ~10 minutes on first run\n\nimport os\nimport sys\nimport time\nimport subprocess\nfrom IPython.display import clear_output, HTML\n\ndef print_step(emoji, title):\n    print(f\"\\n{emoji} {title}\")\n    print(\"=\"*60)\n\ndef run_cmd(cmd, description):\n    \"\"\"Run command and show status\"\"\"\n    print(f\"  {description}...\", end=\"\", flush=True)\n    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n    if result.returncode == 0:\n        print(\" ‚úÖ\")\n        return True\n    else:\n        print(f\" ‚ùå Error: {result.stderr}\")\n        return False\n\nprint(\"=\"*70)\nprint(\"     üé® MASUKA V2 - Complete Setup\")\nprint(\"=\"*70)\n\n# STEP 1: GPU Check\nprint_step(\"1Ô∏è‚É£\", \"Checking GPU\")\nresult = subprocess.run(\"nvidia-smi -L\", shell=True, capture_output=True, text=True)\nif result.returncode == 0:\n    gpu_info = result.stdout.strip()\n    print(f\"  {gpu_info}\")\n    print(\"  ‚úÖ GPU detected!\")\nelse:\n    print(\"  ‚ùå No GPU! Go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n    sys.exit(1)\n\n# STEP 2: Clone/Update Repository\nprint_step(\"2Ô∏è‚É£\", \"Setting up Repository\")\nif not os.path.exists('/content/masuka-v2'):\n    run_cmd(\"git clone https://github.com/SamuelD27/masuka.git /content/masuka-v2\", \"Cloning repository\")\nelse:\n    print(\"  ‚úÖ Repository exists\")\n    os.chdir('/content/masuka-v2')\n    run_cmd(\"git pull origin main\", \"Updating repository\")\n\nos.chdir('/content/masuka-v2')\nprint(\"  ‚úÖ Working directory: /content/masuka-v2\")\n\n# STEP 3: Install PyTorch\nprint_step(\"3Ô∏è‚É£\", \"Installing PyTorch & Dependencies\")\nprint(\"  This may take 3-5 minutes...\")\n\nprint(\"  üßπ Cleaning existing installations...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"-q\", \"torch\", \"torchvision\", \"torchaudio\"], capture_output=True)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"cache\", \"purge\"], capture_output=True)\n\nprint(\"  üì¶ Installing PyTorch 2.4.1 + TorchVision 0.19.1...\")\nresult = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch==2.4.1\", \"torchvision==0.19.1\", \"torchaudio==2.4.1\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"], capture_output=True, text=True)\nif result.returncode != 0:\n    print(f\"  ‚ùå PyTorch installation failed!\")\n    sys.exit(1)\nprint(\"  ‚úÖ PyTorch installed\")\n\nprint(\"  üì¶ Installing backend dependencies...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"backend/requirements.txt\"], capture_output=True)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\"], capture_output=True)\nprint(\"  ‚úÖ All dependencies installed\")\n\n# Verify installations\nprint(\"\\n  üîç Verifying installations...\")\nverify_script = \"\"\"\\nimport torch, torchvision\\nfrom diffusers import FluxPipeline\\nimport fastapi, celery, pydantic\\nprint(f\"‚úì PyTorch: {torch.__version__}\")\\nprint(f\"‚úì TorchVision: {torchvision.__version__}\")\\nif torch.cuda.is_available():\\n    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\\n    print(f\"‚úì CUDA: {torch.version.cuda}\")\\n\"\"\"\nwith open('/tmp/verify.py', 'w') as f:\n    f.write(verify_script)\nresult = subprocess.run([sys.executable, '/tmp/verify.py'], capture_output=True, text=True)\nfor line in result.stdout.strip().split('\\n'):\n    print(f\"  {line}\")\ngpu_name = \"Unknown GPU\"\nfor line in result.stdout.split('\\n'):\n    if \"GPU:\" in line:\n        gpu_name = line.split(\"GPU: \")[1].strip()\nprint(\"  ‚úÖ All imports verified!\")\n\n# STEP 4: Install SimpleTuner\nprint_step(\"4Ô∏è‚É£\", \"Installing SimpleTuner\")\nif not os.path.exists('/content/SimpleTuner'):\n    run_cmd(\"git clone -q https://github.com/bghira/SimpleTuner /content/SimpleTuner\", \"Cloning SimpleTuner\")\n    print(\"  üì¶ Installing SimpleTuner package...\", end=\"\", flush=True)\n    os.chdir('/content/SimpleTuner')\n    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", \".\"], capture_output=True)\n    print(\" ‚úÖ\")\n    os.chdir('/content/masuka-v2')\nelse:\n    print(\"  ‚úÖ SimpleTuner already installed\")\n\n# STEP 5: Setup PostgreSQL\nprint_step(\"5Ô∏è‚É£\", \"Setting up PostgreSQL\")\nrun_cmd(\"apt-get update -qq && apt-get install -y -qq postgresql postgresql-contrib\", \"Installing PostgreSQL\")\nrun_cmd(\"service postgresql start\", \"Starting PostgreSQL\")\ntime.sleep(2)\n\ncommands = [\"DROP DATABASE IF EXISTS masuka;\", \"DROP USER IF EXISTS masuka;\", \"CREATE USER masuka WITH PASSWORD 'password123';\", \"CREATE DATABASE masuka OWNER masuka;\", \"GRANT ALL PRIVILEGES ON DATABASE masuka TO masuka;\"]\nfor cmd in commands:\n    subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", cmd], capture_output=True)\n\nprint(\"  üîß Configuring authentication...\", end=\"\", flush=True)\nconfig_paths = ['/etc/postgresql/15/main/pg_hba.conf', '/etc/postgresql/14/main/pg_hba.conf', '/etc/postgresql/13/main/pg_hba.conf']\nconfig_file = None\nfor path in config_paths:\n    if os.path.exists(path):\n        config_file = path\n        break\nif config_file:\n    with open(config_file, 'r') as f:\n        content = f.read()\n    import re\n    content = re.sub(r'local\\s+all\\s+all\\s+peer', 'local   all             all                                     md5', content)\n    content = re.sub(r'host\\s+all\\s+all\\s+127\\.0\\.0\\.1/32\\s+ident', 'host    all             all             127.0.0.1/32            md5', content)\n    with open('/tmp/pg_hba.conf', 'w') as f:\n        f.write(content)\n    subprocess.run(['sudo', 'cp', '/tmp/pg_hba.conf', config_file], capture_output=True)\n    subprocess.run(['sudo', 'service', 'postgresql', 'restart'], capture_output=True)\n    time.sleep(2)\nprint(\" ‚úÖ\")\nprint(\"  ‚úÖ Database 'masuka' created and configured\")\n\n# STEP 6: Setup Redis\nprint_step(\"6Ô∏è‚É£\", \"Setting up Redis\")\nrun_cmd(\"apt-get install -y -qq redis-server\", \"Installing Redis\")\nrun_cmd(\"redis-server --daemonize yes\", \"Starting Redis\")\ntime.sleep(1)\nrun_cmd(\"redis-cli ping\", \"Testing Redis\")\n\n# STEP 7: Configure Environment\nprint_step(\"7Ô∏è‚É£\", \"Configuring Environment\")\nenv_content = \"\"\"APP_NAME=MASUKA V2\\nDEBUG=true\\nDATABASE_URL=postgresql://masuka:password123@localhost:5432/masuka\\nREDIS_URL=redis://localhost:6379/0\\nCELERY_BROKER_URL=redis://localhost:6379/0\\nCELERY_RESULT_BACKEND=redis://localhost:6379/0\\nSECRET_KEY=colab-secret-key\\nALGORITHM=HS256\\nACCESS_TOKEN_EXPIRE_MINUTES=1440\\nS3_BUCKET=your-bucket\\nAWS_ACCESS_KEY_ID=your-key\\nAWS_SECRET_ACCESS_KEY=your-secret\\nS3_REGION=auto\\nHF_TOKEN=hf_your_token\\nSIMPLETUNER_PATH=/content/SimpleTuner\\nMODELS_PATH=/content/models\\nTEMP_PATH=/tmp/masuka\\nCORS_ORIGINS=*\"\"\"\nos.makedirs('/content/masuka-v2/backend', exist_ok=True)\nwith open('/content/masuka-v2/backend/.env', 'w') as f:\n    f.write(env_content)\nprint(\"  ‚úÖ Environment configured\")\n\n# STEP 8: Initialize Directories\nprint_step(\"8Ô∏è‚É£\", \"Initializing Directories\")\ndirectories = ['/tmp/masuka/uploads', '/tmp/masuka/training', '/tmp/masuka/generated', '/tmp/masuka/model_cache', '/content/models']\nfor directory in directories:\n    os.makedirs(directory, exist_ok=True)\nprint(\"  ‚úÖ Directories created\")\n\n# STEP 9: Start FastAPI Backend\nprint_step(\"9Ô∏è‚É£\", \"Starting FastAPI Backend\")\nos.chdir('/content/masuka-v2/backend')\n\n# Kill any existing process\nsubprocess.run(['pkill', '-f', 'uvicorn'], capture_output=True)\ntime.sleep(3)\n\n# Verify database is ready first\nprint(\"  üîç Verifying database connection...\")\nresult = subprocess.run(\n    ['psql', '-U', 'masuka', '-d', 'masuka', '-h', 'localhost', '-c', 'SELECT 1;'],\n    capture_output=True,\n    text=True,\n    env={'PGPASSWORD': 'password123'}\n)\nif result.returncode == 0:\n    print(\"  ‚úÖ Database ready\")\nelse:\n    print(\"  ‚ö†Ô∏è Database not ready, waiting 5 seconds...\")\n    time.sleep(5)\n\n# Test backend import before starting\nprint(\"  üîç Testing backend import...\")\ntest_import = subprocess.run(\n    [sys.executable, '-c',\n     'import sys; sys.path.insert(0, \"/content/masuka-v2/backend\"); from app.main import app; print(\"OK\")'],\n    capture_output=True,\n    text=True,\n    cwd='/content/masuka-v2/backend'\n)\n\nif test_import.returncode != 0:\n    print(f\"  ‚ùå Backend import failed!\")\n    print(f\"  Error: {test_import.stderr}\")\n    print(\"\\n  Most common causes:\")\n    print(\"  1. Missing dependencies (torch, diffusers)\")\n    print(\"  2. Database connection issues\")\n    print(\"  3. Import errors in backend code\")\n    sys.exit(1)\nprint(\"  ‚úÖ Backend import successful\")\n\n# Start backend with error capture\nprint(\"  üöÄ Starting backend process...\")\nbackend_process = subprocess.Popen(\n    ['uvicorn', 'app.main:app', '--host', '0.0.0.0', '--port', '8000', '--log-level', 'info'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.PIPE,\n    text=True\n)\n\n# Check if process died immediately\ntime.sleep(3)\nif backend_process.poll() is not None:\n    # Process exited immediately - capture error\n    stdout, stderr = backend_process.communicate()\n    print(f\"  ‚ùå Backend crashed immediately!\")\n    print(f\"\\n  Error output:\")\n    print(stderr[-500:] if len(stderr) > 500 else stderr)  # Last 500 chars\n    sys.exit(1)\n\n# Wait for backend to be ready with retry logic\nprint(\"  ‚è≥ Waiting for backend to start...\")\nimport requests\nbackend_ok = False\nfor i in range(8):  # 40 seconds total\n    time.sleep(5)\n    try:\n        response = requests.get('http://localhost:8000/health', timeout=3)\n        if response.status_code == 200:\n            health = response.json()\n            print(f\"  ‚úÖ Backend running: {health['app']} v{health['version']} (after {(i+1)*5}s)\")\n            backend_ok = True\n            break\n    except:\n        print(f\"     Attempt {i+1}/8...\", end=\"\\r\")\n        continue\n\nif not backend_ok:\n    print(f\"\\n  ‚ùå Backend did not start after 40 seconds\")\n    print(\"\\n  Checking process status...\")\n    if backend_process.poll() is not None:\n        # Process died during wait\n        stdout, stderr = backend_process.communicate()\n        print(f\"  Process exited with code: {backend_process.poll()}\")\n        print(f\"\\n  Last error output:\")\n        print(stderr[-500:] if len(stderr) > 500 else stderr)\n    else:\n        # Process still running but not responding\n        print(f\"  Process is still running but not responding\")\n        print(f\"  Try waiting longer or check logs with:\")\n        print(f\"  !cat /proc/$(pgrep -f uvicorn)/fd/2\")\n    sys.exit(1)\n\n# STEP 10: Start Celery Worker\nprint_step(\"üîü\", \"Starting Celery Worker\")\nsubprocess.run(['pkill', '-f', 'celery'], capture_output=True)\ntime.sleep(2)\ncelery_process = subprocess.Popen(['celery', '-A', 'app.tasks.celery_app', 'worker', '--loglevel=info', '--concurrency=1', '-Q', 'training,generation'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\ntime.sleep(5)\nprint(f\"  ‚úÖ Celery worker started (GPU: {gpu_name})\")\n\n# STEP 11: Create Ngrok Tunnel\nprint_step(\"1Ô∏è‚É£1Ô∏è‚É£\", \"Creating Public URL\")\nfrom pyngrok import ngrok\nngrok.set_auth_token(\"33u4PSfJRAAdkBVl0lmMTo7LebK_815Q5PcJK6h68hM5PUAyM\")\nngrok.kill()\ntime.sleep(2)\npublic_url = ngrok.connect(8000)\nprint(\"  ‚úÖ Tunnel created\")\n\n# FINAL OUTPUT\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéâ MASUKA V2 Setup Complete!\")\nprint(\"=\"*70)\nprint(f\"\\nüì° Your Public API URL:\\n   {public_url}\")\nprint(f\"\\nüìö Important Links:\")\nprint(f\"   ‚Ä¢ API Documentation: {public_url}/docs\")\nprint(f\"   ‚Ä¢ Health Check: {public_url}/health\")\nprint(\"\\n‚úÖ Services Running:\")\nprint(f\"   ‚Ä¢ PostgreSQL (md5 auth)\")\nprint(f\"   ‚Ä¢ Redis\")\nprint(f\"   ‚Ä¢ FastAPI Backend\")\nprint(f\"   ‚Ä¢ Celery Worker (GPU: {gpu_name})\")\nprint(f\"   ‚Ä¢ SimpleTuner\")\nprint(\"\\n‚ö†Ô∏è  Keep this notebook running!\")\nprint(\"\\nüìñ Next Steps:\")\nprint(\"   1. Run Cell 2 to test API\")\nprint(\"   2. Run Cell 5 to upload images\")\nprint(\"   3. Run Cell 6 to train LoRA\")\nprint(\"   4. Run Cell 7 to generate images\")\nprint(\"=\"*70)\n\n# Store for other cells\nAPI_URL = str(public_url)\nBACKEND_PROCESS = backend_process\nCELERY_PROCESS = celery_process\nprint(f\"\\n‚úÖ API_URL stored: {API_URL}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell2_test",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üß™ CELL 2: Test API - Verify Everything Works\n",
    "#@markdown Run this cell to test all endpoints and verify setup is working correctly.\n",
    "\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üß™ MASUKA V2 - API Testing\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    api_url = API_URL\n",
    "    print(f\"\\nüì° Using API URL: {api_url}\")\n",
    "except NameError:\n",
    "    from pyngrok import ngrok\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    if tunnels:\n",
    "        api_url = tunnels[0].public_url\n",
    "        print(f\"‚úÖ Found tunnel: {api_url}\")\n",
    "    else:\n",
    "        print(\"‚ùå No tunnel found. Run Cell 1 first.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "\n",
    "# Test endpoints\n",
    "print(\"\\n1Ô∏è‚É£ Testing Health Endpoint...\")\n",
    "response = requests.get(f\"{api_url}/health\", timeout=10)\n",
    "if response.status_code == 200:\n",
    "    health = response.json()\n",
    "    print(f\"  ‚úÖ Status: {health['status']}\")\n",
    "    print(f\"  ‚úÖ App: {health['app']} v{health['version']}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Testing Models API...\")\n",
    "response = requests.get(f\"{api_url}/api/models/\", timeout=10)\n",
    "if response.status_code == 200:\n",
    "    models = response.json()\n",
    "    print(f\"  ‚úÖ Models API working\")\n",
    "    print(f\"  ‚úÖ Current models: {len(models)}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Testing Datasets API...\")\n",
    "response = requests.get(f\"{api_url}/api/datasets/\", timeout=10)\n",
    "if response.status_code == 200:\n",
    "    datasets = response.json()\n",
    "    print(f\"  ‚úÖ Datasets API working\")\n",
    "    print(f\"  ‚úÖ Current datasets: {len(datasets)}\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Checking Services...\")\n",
    "result = subprocess.run(['pgrep', '-f', 'uvicorn'], capture_output=True, text=True)\n",
    "if result.stdout.strip():\n",
    "    print(f\"  ‚úÖ FastAPI backend running\")\n",
    "\n",
    "result = subprocess.run(['pgrep', '-f', 'celery.*worker'], capture_output=True, text=True)\n",
    "if result.stdout.strip():\n",
    "    print(f\"  ‚úÖ Celery worker running\")\n",
    "\n",
    "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(f\"  ‚úÖ GPU: {result.stdout.strip()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Your MASUKA V2 API is ready!\")\n",
    "print(f\"\\nüîó API Docs: {api_url}/docs\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell3_utils",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üîß CELL 3: Utility Commands (Reference)\n",
    "#@markdown Useful commands for managing your MASUKA V2 instance\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîß MASUKA V2 - Utility Commands\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìù Useful Commands:\")\n",
    "print(\"\\n1. Check GPU: !nvidia-smi\")\n",
    "print(\"2. Restart Backend: !pkill -f uvicorn && cd /content/masuka-v2/backend && uvicorn app.main:app --host 0.0.0.0 --port 8000 &\")\n",
    "print(\"3. Restart Celery: !pkill -f celery && cd /content/masuka-v2/backend && celery -A app.tasks.celery_app worker --loglevel=info -Q training,generation &\")\n",
    "print(\"4. Check Database: !PGPASSWORD=password123 psql -U masuka -d masuka -h localhost -c '\\\\dt'\")\n",
    "print(\"5. View Redis Info: !redis-cli info\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell4_diagnostic",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üîç CELL 4: Diagnostic Tool (Run if issues occur)\n",
    "#@markdown Comprehensive diagnostics to identify problems\n",
    "\n",
    "import subprocess\n",
    "import requests\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç MASUKA V2 - Diagnostics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Backend Process...\")\n",
    "result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)\n",
    "uvicorn_procs = [l for l in result.stdout.split('\\n') if 'uvicorn' in l and 'grep' not in l]\n",
    "if uvicorn_procs:\n",
    "    print(\"  ‚úÖ Backend running\")\n",
    "else:\n",
    "    print(\"  ‚ùå Backend not running!\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Backend Response...\")\n",
    "try:\n",
    "    response = requests.get('http://localhost:8000/health', timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"  ‚úÖ Backend responding: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Database...\")\n",
    "result = subprocess.run(['psql', '-U', 'masuka', '-d', 'masuka', '-h', 'localhost', '-c', 'SELECT 1;'], capture_output=True, text=True, env={'PGPASSWORD': 'password123'})\n",
    "if result.returncode == 0:\n",
    "    print(\"  ‚úÖ Database connection OK\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Database error\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Redis...\")\n",
    "result = subprocess.run(['redis-cli', 'ping'], capture_output=True, text=True)\n",
    "if 'PONG' in result.stdout:\n",
    "    print(\"  ‚úÖ Redis OK\")\n",
    "else:\n",
    "    print(\"  ‚ùå Redis not responding\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ Celery...\")\n",
    "result = subprocess.run(['pgrep', '-f', 'celery.*worker'], capture_output=True, text=True)\n",
    "if result.stdout.strip():\n",
    "    print(f\"  ‚úÖ Celery running\")\n",
    "else:\n",
    "    print(\"  ‚ùå Celery not running!\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ GPU...\")\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"  ‚úÖ GPU detected\")\n",
    "else:\n",
    "    print(\"  ‚ùå No GPU!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÅ Diagnostic Complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell5_upload",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üì∏ CELL 5: Upload Images & Create Dataset\n",
    "#@markdown Upload your training images and create a dataset\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Configuration:\n",
    "dataset_name = \"My Custom LoRA\" #@param {type:\"string\"}\n",
    "trigger_word = \"mysubject\" #@param {type:\"string\"}\n",
    "dataset_description = \"Training data for my custom subject\" #@param {type:\"string\"}\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from google.colab import files\n",
    "import json\n",
    "\n",
    "try:\n",
    "    api_url = API_URL\n",
    "except NameError:\n",
    "    from pyngrok import ngrok\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    if tunnels:\n",
    "        api_url = tunnels[0].public_url\n",
    "    else:\n",
    "        print(\"‚ùå No API URL found. Run Cell 1 first.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üì∏ MASUKA V2 - Upload Images & Create Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Upload images\n",
    "print(\"\\n1Ô∏è‚É£ Upload your training images...\")\n",
    "print(\"   Select 10-30 images of your subject\")\n",
    "print(\"   Requirements:\")\n",
    "print(\"   ‚Ä¢ Same subject in different poses/lighting\")\n",
    "print(\"   ‚Ä¢ High quality (1024x1024 or larger)\")\n",
    "print(\"   ‚Ä¢ Diverse backgrounds and angles\")\n",
    "print(\"\\n‚è≥ File picker will open...\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "print(f\"\\n‚úÖ Uploaded {len(uploaded)} images\")\n",
    "\n",
    "# Move images to upload directory\n",
    "upload_dir = '/tmp/masuka/uploads/training_images'\n",
    "os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "image_paths = []\n",
    "for filename in uploaded.keys():\n",
    "    src = f\"/content/{filename}\"\n",
    "    dst = f\"{upload_dir}/{filename}\"\n",
    "    os.rename(src, dst)\n",
    "    image_paths.append(dst)\n",
    "\n",
    "print(f\"‚úÖ Saved images to {upload_dir}\")\n",
    "\n",
    "# Step 2: Create dataset via API\n",
    "print(\"\\n2Ô∏è‚É£ Creating dataset via API...\")\n",
    "response = requests.post(\n",
    "    f\"{api_url}/api/datasets/\",\n",
    "    json={\n",
    "        \"name\": dataset_name,\n",
    "        \"description\": dataset_description\n",
    "    },\n",
    "    timeout=10\n",
    ")\n",
    "\n",
    "if response.status_code in [200, 201]:\n",
    "    dataset = response.json()\n",
    "    dataset_id = dataset['id']\n",
    "    print(f\"‚úÖ Dataset created: {dataset['name']}\")\n",
    "    print(f\"   Dataset ID: {dataset_id}\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to create dataset: {response.status_code}\")\n",
    "    print(response.text)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Step 3: Upload images to dataset\n",
    "print(\"\\n3Ô∏è‚É£ Uploading images to dataset...\")\n",
    "files_data = []\n",
    "for image_path in image_paths:\n",
    "    with open(image_path, 'rb') as f:\n",
    "        files_data.append(('files', (os.path.basename(image_path), f.read(), 'image/jpeg')))\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{api_url}/api/datasets/{dataset_id}/upload\",\n",
    "    files=files_data,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "if response.status_code in [200, 201]:\n",
    "    print(f\"‚úÖ Uploaded {len(image_paths)} images to dataset\")\n",
    "else:\n",
    "    print(f\"‚ùå Upload failed: {response.status_code}\")\n",
    "    print(response.text)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ Dataset Ready!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Dataset Name: {dataset_name}\")\n",
    "print(f\"   ‚Ä¢ Dataset ID: {dataset_id}\")\n",
    "print(f\"   ‚Ä¢ Trigger Word: {trigger_word}\")\n",
    "print(f\"   ‚Ä¢ Images: {len(image_paths)}\")\n",
    "print(f\"\\nüìñ Next Step:\")\n",
    "print(f\"   Run Cell 6 to train your LoRA model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store for training cell\n",
    "DATASET_ID = dataset_id\n",
    "TRIGGER_WORD = trigger_word\n",
    "DATASET_NAME = dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell6_train",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üèãÔ∏è CELL 6: Train LoRA Model\n",
    "#@markdown Start training your custom LoRA model\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Training Configuration:\n",
    "model_name = \"my_lora_v1\" #@param {type:\"string\"}\n",
    "training_steps = 1000 #@param {type:\"integer\"}\n",
    "learning_rate = 0.0001 #@param {type:\"number\"}\n",
    "batch_size = 1 #@param {type:\"integer\"}\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "try:\n",
    "    api_url = API_URL\n",
    "    dataset_id = DATASET_ID\n",
    "    trigger_word = TRIGGER_WORD\n",
    "except NameError:\n",
    "    print(\"‚ùå Missing variables. Run Cell 1 and Cell 5 first.\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üèãÔ∏è MASUKA V2 - Train LoRA Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Training Configuration:\")\n",
    "print(f\"   ‚Ä¢ Model Name: {model_name}\")\n",
    "print(f\"   ‚Ä¢ Trigger Word: {trigger_word}\")\n",
    "print(f\"   ‚Ä¢ Dataset ID: {dataset_id}\")\n",
    "print(f\"   ‚Ä¢ Training Steps: {training_steps}\")\n",
    "print(f\"   ‚Ä¢ Learning Rate: {learning_rate}\")\n",
    "print(f\"   ‚Ä¢ Batch Size: {batch_size}\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\n1Ô∏è‚É£ Starting training...\")\n",
    "response = requests.post(\n",
    "    f\"{api_url}/api/training/start\",\n",
    "    json={\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"model_name\": model_name,\n",
    "        \"trigger_word\": trigger_word,\n",
    "        \"steps\": training_steps,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size\n",
    "    },\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "if response.status_code in [200, 201]:\n",
    "    training_session = response.json()\n",
    "    session_id = training_session['id']\n",
    "    print(f\"‚úÖ Training started!\")\n",
    "    print(f\"   Session ID: {session_id}\")\n",
    "else:\n",
    "    print(f\"‚ùå Training failed to start: {response.status_code}\")\n",
    "    print(response.text)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Monitor training progress\n",
    "print(\"\\n2Ô∏è‚É£ Monitoring training progress...\")\n",
    "print(\"   This will take 10-30 minutes depending on steps\")\n",
    "print(\"   ‚è≥ Progress updates:\")\n",
    "print()\n",
    "\n",
    "last_status = None\n",
    "while True:\n",
    "    time.sleep(30)  # Check every 30 seconds\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{api_url}/api/training/status\",\n",
    "            params={\"session_id\": session_id},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            status = response.json()\n",
    "            current_status = status.get('status', 'unknown')\n",
    "            progress = status.get('progress', 0)\n",
    "            \n",
    "            if current_status != last_status:\n",
    "                print(f\"   Status: {current_status} - Progress: {progress:.1f}%\")\n",
    "                last_status = current_status\n",
    "            \n",
    "            if current_status == 'completed':\n",
    "                print(\"\\n‚úÖ Training completed successfully!\")\n",
    "                model_id = status.get('model_id')\n",
    "                break\n",
    "            elif current_status == 'failed':\n",
    "                print(f\"\\n‚ùå Training failed: {status.get('error', 'Unknown error')}\")\n",
    "                import sys\n",
    "                sys.exit(1)\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Status check returned: {response.status_code}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Status check error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ Training Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   ‚Ä¢ Model Name: {model_name}\")\n",
    "print(f\"   ‚Ä¢ Model ID: {model_id}\")\n",
    "print(f\"   ‚Ä¢ Trigger Word: {trigger_word}\")\n",
    "print(f\"   ‚Ä¢ Training Steps: {training_steps}\")\n",
    "print(f\"\\nüìñ Next Step:\")\n",
    "print(f\"   Run Cell 7 to generate images with your model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store for generation cell\n",
    "MODEL_ID = model_id\n",
    "MODEL_NAME = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell7_generate",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üé® CELL 7: Generate Images\n",
    "#@markdown Generate images using your trained LoRA or base Flux model\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Generation Configuration:\n",
    "prompt = \"mysubject in a beautiful garden, sunset lighting, highly detailed\" #@param {type:\"string\"}\n",
    "use_trained_lora = True #@param {type:\"boolean\"}\n",
    "num_inference_steps = 28 #@param {type:\"integer\"}\n",
    "guidance_scale = 3.5 #@param {type:\"number\"}\n",
    "width = 1024 #@param {type:\"integer\"}\n",
    "height = 1024 #@param {type:\"integer\"}\n",
    "num_images = 1 #@param {type:\"integer\"}\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import Image, display\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    api_url = API_URL\n",
    "except NameError:\n",
    "    from pyngrok import ngrok\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    if tunnels:\n",
    "        api_url = tunnels[0].public_url\n",
    "    else:\n",
    "        print(\"‚ùå No API URL found. Run Cell 1 first.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "\n",
    "# Get model ID if using trained LoRA\n",
    "model_id = None\n",
    "if use_trained_lora:\n",
    "    try:\n",
    "        model_id = MODEL_ID\n",
    "        print(f\"Using trained model: {MODEL_NAME} ({model_id})\")\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è No trained model found. Using base Flux model.\")\n",
    "        print(\"   Run Cell 6 first to train a LoRA.\")\n",
    "        use_trained_lora = False\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üé® MASUKA V2 - Generate Images\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Generation Configuration:\")\n",
    "print(f\"   ‚Ä¢ Prompt: {prompt}\")\n",
    "print(f\"   ‚Ä¢ Model: {MODEL_NAME if use_trained_lora else 'Base Flux'}\")\n",
    "print(f\"   ‚Ä¢ Size: {width}x{height}\")\n",
    "print(f\"   ‚Ä¢ Steps: {num_inference_steps}\")\n",
    "print(f\"   ‚Ä¢ Guidance: {guidance_scale}\")\n",
    "print(f\"   ‚Ä¢ Count: {num_images}\")\n",
    "\n",
    "# Generate images\n",
    "print(\"\\n‚è≥ Generating images...\")\n",
    "print(\"   This will take 10-30 seconds per image\")\n",
    "print()\n",
    "\n",
    "for i in range(num_images):\n",
    "    print(f\"Generating image {i+1}/{num_images}...\")\n",
    "    \n",
    "    generation_data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"num_inference_steps\": num_inference_steps,\n",
    "        \"guidance_scale\": guidance_scale,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    }\n",
    "    \n",
    "    if use_trained_lora and model_id:\n",
    "        generation_data[\"model_id\"] = model_id\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{api_url}/api/generate/\",\n",
    "            json=generation_data,\n",
    "            timeout=120\n",
    "        )\n",
    "        \n",
    "        if response.status_code in [200, 201]:\n",
    "            result = response.json()\n",
    "            image_url = result.get('image_url')\n",
    "            asset_id = result.get('id')\n",
    "            \n",
    "            print(f\"  ‚úÖ Generated image {i+1}\")\n",
    "            print(f\"     Asset ID: {asset_id}\")\n",
    "            print(f\"     URL: {image_url}\")\n",
    "            \n",
    "            # Download and display image\n",
    "            if image_url:\n",
    "                img_response = requests.get(image_url, timeout=30)\n",
    "                if img_response.status_code == 200:\n",
    "                    # Save locally\n",
    "                    output_path = f\"/content/generated_image_{i+1}.png\"\n",
    "                    with open(output_path, 'wb') as f:\n",
    "                        f.write(img_response.content)\n",
    "                    \n",
    "                    # Display in notebook\n",
    "                    print(f\"\\nüì∏ Image {i+1}:\")\n",
    "                    display(Image(filename=output_path))\n",
    "                    print(f\"\\nSaved to: {output_path}\\n\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Generation failed: {response.status_code}\")\n",
    "            print(f\"     {response.text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ Generation Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Generated {num_images} image(s)\")\n",
    "print(f\"\\nüí° Tips for better results:\")\n",
    "print(f\"   ‚Ä¢ Use your trigger word: '{TRIGGER_WORD if use_trained_lora else 'N/A'}'\")\n",
    "print(f\"   ‚Ä¢ Experiment with different prompts\")\n",
    "print(f\"   ‚Ä¢ Try different guidance scales (2.0-5.0)\")\n",
    "print(f\"   ‚Ä¢ Adjust inference steps for speed/quality\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## üéì Usage Guide\n",
    "\n",
    "### Complete Workflow:\n",
    "\n",
    "1. **Setup** (Cell 1) - Run once per session (~10 min)\n",
    "2. **Test** (Cell 2) - Verify everything works\n",
    "3. **Upload** (Cell 5) - Upload 10-30 training images\n",
    "4. **Train** (Cell 6) - Train your LoRA (10-30 min)\n",
    "5. **Generate** (Cell 7) - Create images with your model\n",
    "\n",
    "### Tips:\n",
    "\n",
    "- **Training Images:** Use 10-30 high-quality images of the same subject\n",
    "- **Trigger Word:** Choose something unique (e.g., \"johnperson\", \"mycar\")\n",
    "- **Training Steps:** 1000-2000 for most subjects\n",
    "- **Generation:** Include trigger word in prompt for best results\n",
    "\n",
    "### Troubleshooting:\n",
    "\n",
    "- Run **Cell 4** for diagnostics\n",
    "- Check **Cell 3** for utility commands\n",
    "- Keep notebook running during training\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources:\n",
    "\n",
    "- **API Docs:** Check Cell 1 output for your `/docs` URL\n",
    "- **SimpleTuner:** https://github.com/bghira/SimpleTuner\n",
    "- **Flux Model:** https://huggingface.co/black-forest-labs/FLUX.1-dev\n",
    "\n",
    "---\n",
    "\n",
    "**MASUKA V2** - Ultra-realistic LoRA training and AI generation platform\n",
    "\n",
    "*Powered by Flux, SimpleTuner, and FastAPI*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}